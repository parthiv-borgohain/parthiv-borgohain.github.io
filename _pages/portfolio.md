---
permalink: /markdown/
title: "Projects"
author_profile: true
redirect_from: 
  - /md/
  - /markdown.html
---
<br>

**Perturbation & Gradient-Based Techniques for Explainable AI**

With increasing complexity in data and success of black-box deep learning models in terms of predictive power, it becomes increasingly difficult but important to be able to make sense of model predictions. We evaluate explain-ability in tensorflow models and compare stability of perturbation-based feature attribution methods such as LIME, SHAP and Counterfactual Explanations versus gradient-based methods like DeepLift, Integrated Gradients, SmoothGrad, etc.

[Code](https://github.com/abhinav-sharma-6167/Advanced-ML-and-XAI/tree/main/Project)
| [Medium](https://medium.com/@abhinav_utexas/explainable-ai-e3cf209af5fc)
| [Papers](https://github.com/abhinav-sharma-6167/Advanced-ML-and-XAI/tree/main/Research%20Papers/Explainable%20AI)

---

**Brand Engagement Analysis - NLP and Image analytics**

Crawled images and captions from Instagram posts of Nike and Adidas to study the social media engagement strategy of both companies.
Key attributes are engineering by obtaining labels, presence of people, sentiment from images (GCP Vision API) ; prominent phrases using named entity recognition, key topics using Latent Dirichlet allocation on the captions. The number of likes and comments were regressed against all these attributes to understand the distinguishing factors of highly engaging posts.

[Code](https://github.com/vicgpt/Unstructured-Data-Analytics/tree/main/Project)
| [Report](https://github.com/vicgpt/Unstructured-Data-Analytics/blob/main/Project/Brand-Analytics.pdf)

---

**Causal Inference in distilling Halo effects from Brand perceptions**

Explored survey data for 2012 United States presidential election wherein latent variables such as probable predilection towards specific candidate as well as halo effect (tendency for positive impression to spill over into opinions in other areas) posed as key modeling challenges. Structural Equation Models were formulated to statistically prove the impact and directionality of latent driver variables onto brand (candidate) preferences while also quantifying their ‘spillover effect’ into other independent driver variables.

[Code](https://github.com/abhinav-sharma-6167/Causal-Inference-for-Brand-Assessment/blob/main/halo%20effect.ipynb)
| [Report](https://github.com/abhinav-sharma-6167/Causal-Inference-for-Brand-Assessment/blob/main/Marketing%20Project%20slides%20v1.pdf)

---

**Customer Reviews based Recommender Engine**

User feedback often helps discover knowledge about the product from the perspective of the consumers. Based on customer reviews of different kinds of beer, a specific beer brand is selected for each user as per the three 'attributes' they care most about. The rec engine formulates the closest match by incorporating both the sentiment score (VADER) as well as cosine similarity scores (from tf-idf vectorizers and spacy embeddings)

[Code](https://github.com/vicgpt/Unstructured-Data-Analytics/blob/main/Assignment%202%20-%20Beer%20review/beer_review.ipynb)

---

**Luxury car market analysis from forum discussions**

In conjunction with cluster analysis, text mining of user generated content can to help brands identify competitors as perceived by the customers. Upon scraping the comments and posts from a car discussion forum we analyzed which car makers are perceived to be similar using MDS. 

[Code](https://github.com/vicgpt/Unstructured-Data-Analytics/blob/main/Assignment%201%20-%20Car%20Brands/Car-Brand-Text-Analytics.ipynb)

---

**M5 Forecasting - Kaggle**

In this competition, the fifth iteration of the Makridakis Competitions, we will use hierarchical sales data from Walmart, to forecast daily sales for the next 28 days. The data, covers stores in three US States (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details. In addition, it has explanatory variables such as price, promotions, day of the week, and special events. Varied boosting models leveraged as benchmarks and deep learning architectures such as RNNs/LSTMs were explored in order to study the lift in accuracy of forecasts.

[Code](https://github.com/abhinav-sharma-6167/Kaggle-M5-Forecasting)
| [Kaggle Problem Statement](https://www.kaggle.com/c/m5-forecasting-accuracy)
